{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import cv2,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "def main():\n",
    "    #To capture the face\n",
    "    face_cap=cv2.CascadeClassifier(\"C:/Python310/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "    #video capture window\n",
    "    video_cap=cv2.VideoCapture(0)\n",
    "    #create window\n",
    "    cv2.namedWindow('frame')\n",
    "    #To run infinitely \n",
    "    while True:\n",
    "        #Reading video data\n",
    "        ret,video_data=video_cap.read()\n",
    "        col=cv2.cvtColor(video_data,cv2.COLOR_BGR2GRAY) #Converting color to gray for easier identification\n",
    "        cv2.setMouseCallback('frame',captureFrame,video_data) #call captureFrame when mouse is clicked\n",
    "        #Scaling\n",
    "        faces=face_cap.detectMultiScale(\n",
    "            col,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30,30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        #Rectangle to detect face\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(video_data,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Showing the result\n",
    "        cv2.imshow('frame',video_data)\n",
    "        #Stops when key 'a' is pressed\n",
    "        if cv2.waitKey(10)==ord('a'):\n",
    "            break\n",
    "    video_cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "path=\"D:/Python Practice/Image processing/Face Detection/images\" #Save images in this directory\n",
    "#You can give your own path\n",
    "def captureFrame(event,x,y,flags,frame): #Function to save images\n",
    "    global count\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK: #If left button is clicked\n",
    "        count+=1\n",
    "        cv2.imwrite(os.path.join(path,'test{}.jpg'.format(count)),frame) # want to save frame here\n",
    "\n",
    "        #Also save it to google drive\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_cap=cv2.VideoCapture(0)\n",
    "# while True:\n",
    "#     ret,video_data=video_cap.read()\n",
    "#     cv2.imshow(\"Live Video\",video_data)\n",
    "#     if cv2.waitKey(10)==ord(\"a\"):\n",
    "#         break\n",
    "# video_cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
